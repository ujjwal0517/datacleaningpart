{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FK8S4C6kG3d"
   },
   "source": [
    "#User-Movie Mapping Sparse Matrix Dataset\n",
    "**No need to execute if dataset_matrix.npz already present**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwqFqla9i55Y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "def save_sparse_matrix(filename, x):\n",
    "    x_coo = x.tocoo()\n",
    "    row = x_coo.row\n",
    "    col = x_coo.col\n",
    "    data = x_coo.data\n",
    "    shape = x_coo.shape\n",
    "    np.savez(filename, row=row, col=col, data=data, shape=shape)\n",
    "\n",
    "def load_sparse_matrix(filename):\n",
    "    y = np.load(filename)\n",
    "    z = sparse.coo_matrix((y['data'], (y['row'], y['col'])), shape=y['shape'])\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92yKigXMi9IR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ratings_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Data/Data/rating_updated_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-3GPQuqi_kT",
    "outputId": "9419be3d-3fb7-42e5-bf66-8543d51acce5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Data/Data/movies_clean.csv')\n",
    "movies_df.iloc[0].movieId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhennMWmi2H_"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "from tqdm import tqdm\n",
    "user_movie = lil_matrix((ratings_df['userId'].unique().shape[0]+1, movies_df.shape[0]))\n",
    "for i in tqdm(range(0,movies_df.shape[0])):\n",
    "  movies = ratings_df[ratings_df.movieId == movies_df.iloc[i]['movieId']]\n",
    "  userIdList = movies['userId'].values\n",
    "  for j in userIdList:\n",
    "        user_movie[j,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlM2_At_kt2p"
   },
   "outputs": [],
   "source": [
    "save_sparse_matrix('tmp/dataset_matrix',user_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-bo0klhIlhz2",
    "outputId": "701d9801-bc60-415f-f55d-bcc602ab8d63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x62000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 70 stored elements in List of Lists format>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = load_sparse_matrix('/content/drive/My Drive/Colab Notebooks/Data/dataset_matrix.npz').tolil()\n",
    "z[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceFjivMGXim7"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#<h2>Model Code</h2>\n",
    "\n",
    "---\n",
    "Download Required:\n",
    "\n",
    "[PreTrained Weights](https://drive.google.com/drive/folders/1-6nMVziieH2K4SqKcJQeiHIwmzV8oRr0?usp=sharing)\n",
    "\n",
    "[User-Movie Sparse Matrix dataset.npz](https://drive.google.com/file/d/1onaqEkTF-Fo7iHTztcJUrep1l5Ht5rz6/view)\n",
    "\n",
    "[Embed Matrix](https://drive.google.com/file/d/1YF4BGBIklBRso-7rAmYkccT9REVTNXbK/view)\n",
    "\n",
    "[Movies Dataset for movie title and index](https://drive.google.com/file/d/1-BvShIGsXyWzvQ_ssXqp9E5wnbnxSXA7/view)\n",
    "\n",
    "Instruction to Execute:\n",
    "1. Download necessary dataset and matrices. Update below cell and fix path according to downloaded data path. \n",
    "2. Execute First Cell to load required datasest, matrices and define VAE model architecture and loss function\n",
    "3. Load PreSaved Weights from checkpoint\n",
    "4. Generate Predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEmTjW4yFb3Z"
   },
   "source": [
    "### Mount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sypIHgDX-ZGL",
    "outputId": "dab508f8-94b5-43c4-cca5-47a1e350fcdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlN09tQovLEW",
    "outputId": "ccdf121a-c95f-4b2d-9e91-0a69a9e65061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive not mounted, so nothing to flush and unmount.\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djaJxw2iPl_P",
    "outputId": "aacb5c9d-5479-4f4c-d477-9c1556d42cd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7CNKhw2TjSG"
   },
   "source": [
    "### <h1>Complete HVAE CODE </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "EJCGrJepQakr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "'''\n",
    "  Load Movies Dataset (62000k)\n",
    "  Load [User -> Movie Map] : [162k,62K] Sparse Matrix \n",
    "  Load [Embed Movie Feature Vector] : [62k, 3] Embedding generated from MVAE\n",
    "'''\n",
    "movies_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Data/movies_clean.csv')\n",
    "\n",
    "embed_movie_feature = np.load('/content/drive/My Drive/Colab Notebooks/Data/embed_movie.npy')\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "def save_sparse_matrix(filename, x):\n",
    "    x_coo = x.tocoo()\n",
    "    row = x_coo.row\n",
    "    col = x_coo.col\n",
    "    data = x_coo.data\n",
    "    shape = x_coo.shape\n",
    "    np.savez(filename, row=row, col=col, data=data, shape=shape)\n",
    "\n",
    "def load_sparse_matrix(filename):\n",
    "    y = np.load(filename)\n",
    "    z = sparse.coo_matrix((y['data'], (y['row'], y['col'])), shape=y['shape'], dtype='int8')   \n",
    "    z = shuffle(z)\n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "  BATCH GENERATOR FOR FIT\n",
    "'''\n",
    "def nn_batch_generator(x,  batch_size, samples_per_epoch):\n",
    "    movie_indices = np.array([range(0,embed_movie_feature.shape[0])])\n",
    "    movie_indices = np.repeat(movie_indices, batch_size, axis = 0)\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    shuffle_index = np.arange(np.shape(x)[0])\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    x =  x[shuffle_index, :]\n",
    "    # y =  y[shuffle_index, :]\n",
    "    while 1:\n",
    "        index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        x_batch = np.array(x[index_batch,:].todense()).astype('float32')\n",
    "        # x_new_batch = x_batch\n",
    "        \n",
    "        counter += 1\n",
    "        yield (x_batch, x_batch)\n",
    "        if (counter >= number_of_batches):\n",
    "            counter=0\n",
    "\n",
    "'''\n",
    "  Generate Predictions\n",
    "'''\n",
    "def generate_predictions(vae, x_train,movies_df,k=20):\n",
    "  INPUT_DIM = x_train.shape[1]\n",
    "\n",
    "  user_ID_rand = int(np.random.randint(x_train.shape[0], size=1))\n",
    "\n",
    "  test = np.array(x_train[user_ID_rand].todense()).reshape((1,INPUT_DIM))\n",
    "  # _,_,z=vae.encoder(test)\n",
    "  test_reconstructed = vae.predict(test)\n",
    "  # test_reconstructed = test_reconstructed.numpy()\n",
    "  top_rated_movies_idx = [i for i, x in enumerate(test[0].tolist()) if x == 1.0]\n",
    "  np.random.shuffle(top_rated_movies_idx)\n",
    "  \n",
    "  print(f'User liked {len(top_rated_movies_idx)} movies')\n",
    "\n",
    "  if len(top_rated_movies_idx) == 0:\n",
    "    print('Emptylist')\n",
    "  else:\n",
    "    # print(top_rated_movies_idx)\n",
    "    sorted_ratings = test_reconstructed[0].tolist()\n",
    "\n",
    "    top_predicted_movies_idx = sorted(range(len(sorted_ratings)), key=lambda i: sorted_ratings[i])[-k:]\n",
    "    # print(top_predicted_movies_idx)\n",
    "\n",
    "  print('Liked')\n",
    "  count=0\n",
    "  for i in top_rated_movies_idx:\n",
    "    print(movies_df.iloc[i]['movieId'], end= ' ')\n",
    "    count += 1\n",
    "    if count >20:\n",
    "      break\n",
    "  print() \n",
    "  print('Predicted')\n",
    "  for i in top_predicted_movies_idx:\n",
    "    print(movies_df.iloc[i]['movieId'], end= ' ')\n",
    "  print() \n",
    "\n",
    "  count=0\n",
    "  for i in top_rated_movies_idx:\n",
    "\n",
    "    print(movies_df[movies_df.movieId == movies_df.iloc[i]['movieId']]['title'].values, end= '->')\n",
    "    print(movies_df[movies_df.movieId ==  movies_df.iloc[i]['movieId']]['genres'].values)\n",
    "    count += 1\n",
    "    if count >20:\n",
    "      break\n",
    "    # print(movies_df[movies_df.movieId ==  movie_dataset_df.columns[i]].head())\n",
    "    # print(i)\n",
    "    # print(movie_dataset_df.columns[i])\n",
    "  print('*'*100)\n",
    "  for i in top_predicted_movies_idx:\n",
    "    print(movies_df[movies_df.movieId == movies_df.iloc[i]['movieId']]['title'].values, end= '->')\n",
    "    print(movies_df[movies_df.movieId ==  movies_df.iloc[i]['movieId']]['genres'].values)\n",
    "\n",
    "\n",
    "def recallatk(x_test, x_test_reconstructed, k):\n",
    "    recall_values = []\n",
    "    total_recall = 0.0\n",
    "    for i in tqdm(range(len(x_test))):\n",
    "        top_rated_movies_idx = [i for i, x in enumerate(x_test[i].tolist()) if x == 1.0]\n",
    "        if len(top_rated_movies_idx) == 0:\n",
    "            continue\n",
    "\n",
    "        sorted_ratings = x_test_reconstructed[i].tolist()\n",
    "        top_predicted_movies_idx = sorted(range(len(sorted_ratings)), key=lambda i: sorted_ratings[i])[-k:]\n",
    "        \n",
    "        sum = 0.0\n",
    "        for i in range(0, k):\n",
    "            if top_predicted_movies_idx[i] in top_rated_movies_idx:\n",
    "                sum+=1.0\n",
    "        recall = sum/float(min(k, len(top_rated_movies_idx)))\n",
    "        total_recall += recall\n",
    "        recall_values.append(recall)\n",
    "    return total_recall/float(len(recall_values))\n",
    "\n",
    "def ndcgatk(x_test, x_test_reconstructed, k):\n",
    "    ndcg_values = []\n",
    "    total_ndcg = 0.0\n",
    "    best  = 0.0\n",
    "    for i in tqdm(range(len(x_test))):\n",
    "        top_rated_movies_idx = [i for i, x in enumerate(x_test[i].tolist()) if x == 1.0]\n",
    "        \n",
    "        if len(top_rated_movies_idx) == 0:\n",
    "            continue\n",
    "        sorted_ratings = x_test_reconstructed[i].tolist()\n",
    "        top_predicted_movies_idx = sorted(range(len(sorted_ratings)), key=lambda i: sorted_ratings[i])[-k:]\n",
    "        sum_ndcg = 0\n",
    "        for i in range(0, k):\n",
    "            if top_predicted_movies_idx[i] in top_rated_movies_idx:\n",
    "                ndcg = 1/(np.math.log(i+2))\n",
    "            else:\n",
    "                ndcg = 0\n",
    "            sum_ndcg += ndcg\n",
    "\n",
    "        total_ndcg += sum_ndcg\n",
    "        ndcg_values.append(sum_ndcg)\n",
    "\n",
    "    ndcg_values = np.array(ndcg_values)\n",
    "    max_ndcg = ndcg_values.max()\n",
    "    ndcg_values = ndcg_values / max_ndcg \n",
    "    total_ndcg = np.sum(ndcg_values)\n",
    "\n",
    "    return total_ndcg/float(len(ndcg_values))\n",
    "\n",
    "\n",
    "import bottleneck as bn\n",
    "import numpy as np\n",
    "\n",
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    Normalized Discounted Cumulative Gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG\n",
    "\n",
    "\n",
    "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    batch_users = X_pred.shape[0]\n",
    "\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ypA_dNJSdhkV"
   },
   "outputs": [],
   "source": [
    "ui_matrix = load_sparse_matrix('/content/drive/My Drive/Colab Notebooks/Data/dataset_matrix.npz')\n",
    "# x_train_coo = x_train\n",
    "# Convert to CSR format from stored COO format remove initial empty \n",
    "# x_train = x_train.tocsr()\n",
    "# x_train = x_train[1:]\n",
    "\n",
    "\n",
    "\n",
    "train_size = ui_matrix.shape[0]-20000\n",
    "train_dataset = ui_matrix[0:train_size]\n",
    "validation_dataset = ui_matrix[train_size: train_size+10000]\n",
    "test_dataset = ui_matrix[train_size+10000:]\n",
    "test_dataset_sparse = test_dataset\n",
    "y_train = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHKdR8RMdzxI",
    "outputId": "027e3d70-83d3-4e49-91bd-d12502518255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142542\n",
      "(162542, 62000)\n",
      "(10000, 62000)\n"
     ]
    }
   ],
   "source": [
    "print(train_size)\n",
    "print(ui_matrix.shape)\n",
    "\n",
    "\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34xB9BBRYkQq"
   },
   "source": [
    "## MULTVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "CO5odkyZbYD-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "layers = tf.keras.layers\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        # epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) \n",
    "\n",
    "\n",
    "def model_encoder(input_dim, latent_dim, dims, vocab_size=1000, embed_dim=3, seq_length=1000, weights=[], **kwargs):\n",
    "  encoder_inputs = keras.Input(shape=(input_dim,), dtype=\"int32\")\n",
    "  # embed = layers.Embedding(vocab_size,embed_dim ,weights=weights, input_length=seq_length, trainable=True)(encoder_inputs)\n",
    "  # flat_embed = layers.Flatten()(embed)\n",
    "\n",
    "  x=layers.Dense(dims[0], activation='tanh',\n",
    "                  name=\"encoder_{}\".format(dims[0]),\n",
    "                  kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                  bias_initializer=tf.keras.initializers.truncated_normal(stddev=0.001),\n",
    "                  # kernel_regularizer='l2'\n",
    "                  ) (encoder_inputs)\n",
    "\n",
    "  for d in dims[1:]:\n",
    "    x = layers.Dense(\n",
    "                  d,\n",
    "                  activation='tanh',\n",
    "                  name=\"encoder_{}\".format(d),\n",
    "                  kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                  bias_initializer=tf.keras.initializers.truncated_normal(stddev=0.001),\n",
    "                  # kernel_regularizer='l2'\n",
    "                  )(x)\n",
    "  z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "  z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "  z = Sampling()([z_mean, z_log_var])\n",
    "  encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "  # encoder.summary()\n",
    "  return encoder\n",
    "\n",
    "def model_decoder(input_dim,latent_dim,dims):\n",
    "  latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "  x=layers.Dense(dims[0], activation='tanh',\n",
    "                  name=\"decoder_{}\".format(dims[0]),\n",
    "                  kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                  bias_initializer=tf.keras.initializers.truncated_normal(stddev=0.001),\n",
    "                  ) (latent_inputs)\n",
    "  for d in dims[1:]:\n",
    "    x = layers.Dense(\n",
    "                  d,\n",
    "                  activation='tanh',\n",
    "                  name=\"decoder_{}\".format(d),\n",
    "                  kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                  bias_initializer=tf.keras.initializers.truncated_normal(stddev=0.001),\n",
    "                  )(x)\n",
    "\n",
    "  decoder_outputs=layers.Dense(input_dim,\n",
    "                  activation='relu',\n",
    "                  name=\"decoder_output_{}\".format(input_dim),\n",
    "                  kernel_initializer=tf.initializers.GlorotUniform(),\n",
    "                  bias_initializer=tf.keras.initializers.truncated_normal(stddev=0.001),\n",
    "                ) (x)\n",
    "  decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "  # decoder.summary()\n",
    "  return decoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MULTVAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder,lam=3e-2,\n",
    "                 total_anneal_steps=200000,\n",
    "                 anneal_cap=0.2, **kwargs):\n",
    "        super(MULTVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.lam = lam\n",
    "        self.total_anneal_steps = total_anneal_steps\n",
    "        self.anneal_cap = anneal_cap\n",
    "        self.update_count=0\n",
    "     \n",
    "    def call(self, inputs, training=False):\n",
    "        # if isinstance(inputs,tf.sparse.SparseTensor):\n",
    "        #     inp = tf.sparse.to_dense(inputs)\n",
    "        # else:\n",
    "        #     inp = inputs\n",
    "        inp = inputs\n",
    "        z_mean, z_log_var, z = self.encoder(inp)\n",
    "        # if training:\n",
    "        #   logits=self.decoder(z)\n",
    "        # else:\n",
    "        #   logits=self.decoder(z_mean)\n",
    "        logits = self.decoder(z)\n",
    "        # Add KL divergence regularization loss.\n",
    "        kl_loss = tf.reduce_mean(-0.5 * tf.reduce_sum(\n",
    "            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1\n",
    "        ,axis=1))\n",
    "\n",
    "\n",
    "      \n",
    "        if self.total_anneal_steps>0:\n",
    "          anneal= min(self.anneal_cap, 1.* (self.update_count/self.total_anneal_steps))\n",
    "        else:\n",
    "          anneal = self.anneal_cap\n",
    "\n",
    "        if training:\n",
    "          self.update_count += 1\n",
    "\n",
    "        # softmax=tf.nn.log_softmax(logits)\n",
    "        # per-user average negative log-likelihood part of loss\n",
    "        # ll_loss = -tf.reduce_sum(tf.gather_nd(softmax, inputs.indices)) / batch_size\n",
    "        loss = 62000* tf.reduce_mean(tf.keras.losses.binary_crossentropy(inp, logits))\n",
    "        # loss = -tf.reduce_mean(tf.reduce_sum(tf.nn.log_softmax(logits)*inputs ,axis=1))\n",
    "        \n",
    "        # loss = tf.reduce_mean(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(tf.cast(inp,\"float32\"), logits), axis=1))\n",
    "\n",
    "        # regularization part of loss\n",
    "        reg_loss = 2 * tf.reduce_sum(self.losses)\n",
    "\n",
    "        # anneal * kl_loss\n",
    "        loss =  loss +  kl_loss\n",
    "        # +  self.lam * reg_loss \n",
    "        self.add_loss(loss)        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ky-nfdElbT9B",
    "outputId": "e43072e7-2410-48cd-a936-afd64acbfed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142542, 62000)\n"
     ]
    }
   ],
   "source": [
    "y_train = train_dataset\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "Ck8ZBtp0fJik"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = y_train.shape[1]\n",
    "EMBED_DIM = 3\n",
    "input_dim=y_train.shape[1]\n",
    "latent_dim = 32\n",
    "encoder_dims=[64]\n",
    "encoder = model_encoder(input_dim,\n",
    "                        latent_dim,\n",
    "                        encoder_dims,\n",
    "                        vocab_size=VOCAB_SIZE,\n",
    "                embed_dim=EMBED_DIM,\n",
    "                weights=[embed_movie_feature],\n",
    "                seq_length=VOCAB_SIZE)\n",
    "encoder_dims.reverse()\n",
    "decoder = model_decoder(input_dim, latent_dim, encoder_dims)\n",
    "\n",
    "# training_steps = len(range(0, y_train.shape[0], BATCH_SIZE))\n",
    "BATCH_SIZE=128\n",
    "TRAIN_SAMPLES_PER_EPOCH = y_train.shape[0]\n",
    "TRAIN_STEPS_PER_EPOCH = np.math.ceil(TRAIN_SAMPLES_PER_EPOCH/BATCH_SIZE)\n",
    "\n",
    "EPOCHS=5\n",
    "ANNEAL_CAP = 0.2\n",
    "TOTAL_ANNEAL_STEPS = (\n",
    "        TRAIN_STEPS_PER_EPOCH * (EPOCHS - int(EPOCHS * 0.2))\n",
    "    ) / ANNEAL_CAP\n",
    "\n",
    "VAL_SAMPLES_PER_EPOCH = validation_dataset.shape[0]\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "VAL_STEPS_PER_EPOCH = np.math.ceil(VAL_SAMPLES_PER_EPOCH/VAL_BATCH_SIZE)\n",
    "\n",
    "\n",
    "vae = MULTVAE(encoder, decoder,total_anneal_steps=TOTAL_ANNEAL_STEPS,\n",
    "                 anneal_cap=ANNEAL_CAP)\n",
    "# out = vae(np.random.random((10,10)).astype('float32'))\n",
    "# vae.summary()\n",
    "# out.shape\n",
    "vae.compile(optimizer='adam')\n",
    "# dataset = np.random.random((10000,1000)).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0GiAqsUOneY",
    "outputId": "5dbb578b-50ff-44b0-b343-2d5ba20dcce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_32 (InputLayer)           [(None, 62000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_64 (Dense)              (None, 64)           3968064     input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 32)           2080        encoder_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 32)           2080        encoder_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sampling_13 (Sampling)          (None, 32)           0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,972,224\n",
      "Trainable params: 3,972,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "k6mf6pbNdrLQ"
   },
   "outputs": [],
   "source": [
    "# vae.decoder.save('/content/drive/My Drive/Colab Notebooks/Data/tmp/model/decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydc8BM7udtpa",
    "outputId": "8b8799bb-fcae-4b0e-dab5-e91d84234754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "decoder_64 (Dense)           (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "decoder_output_62000 (Dense) (None, 62000)             4030000   \n",
      "=================================================================\n",
      "Total params: 4,032,112\n",
      "Trainable params: 4,032,112\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "O4DWDDXn26r7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6z6ZpdyM66O"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "fo49VVhICJBb"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = '/content/drive/My Drive/Colab Notebooks/Data/tmp/training/cp-latest-MULTVAE-TRAIN-WITH_SOFTMAX.h5'\n",
    "\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                              save_weights_only=True, \n",
    "                                              verbose=1, save_freq='epoch',\n",
    "            monitor='loss',\n",
    "            mode='auto',\n",
    "            save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1_5V4OKchPE",
    "outputId": "1ba21cd6-e26e-434d-c5cf-426a01d0fa7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1114/1114 [==============================] - 422s 378ms/step - loss: 840.2264 - val_loss: 630.3154\n",
      "Epoch 2/5\n",
      "1114/1114 [==============================] - 422s 379ms/step - loss: 658.9435 - val_loss: 632.8793\n",
      "Epoch 3/5\n",
      "1114/1114 [==============================] - 418s 375ms/step - loss: 644.6933 - val_loss: 601.8240\n",
      "Epoch 4/5\n",
      "1114/1114 [==============================] - 417s 374ms/step - loss: 623.2432 - val_loss: 656.0333\n",
      "Epoch 5/5\n",
      "1114/1114 [==============================] - 412s 370ms/step - loss: 629.6465 - val_loss: 592.6546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fadb532a080>"
      ]
     },
     "execution_count": 210,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vae.fit(nn_batch_generator(y_train, BATCH_SIZE, TRAIN_SAMPLES_PER_EPOCH) ,\n",
    "        steps_per_epoch=TRAIN_STEPS_PER_EPOCH, \n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data = nn_batch_generator(validation_dataset, VAL_BATCH_SIZE, VAL_SAMPLES_PER_EPOCH),\n",
    "        validation_steps=VAL_STEPS_PER_EPOCH,\n",
    "        # callbacks=[cp_callback]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W58S08ONGm9w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "fLjGy4lpGkm2"
   },
   "outputs": [],
   "source": [
    "# vae.save_weights('/content/drive/My Drive/Colab Notebooks/Data/tmp/training/cp-latest-MULTVAE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hFIvBHqHr2M",
    "outputId": "15284cc8-427a-4a89-9fe3-2525ebd107fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/tmp/model/New/assets\n"
     ]
    }
   ],
   "source": [
    "# vae.save('/content/drive/My Drive/Colab Notebooks/Data/tmp/model/MultVae')\n",
    "vae.save('/content/tmp/model/New')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tfyoPMqeQQH"
   },
   "source": [
    "### LOAD WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4s0-_Y9J0x8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "new_vae = tf.keras.models.load_model('/content/drive/My Drive/Colab Notebooks/Data/tmp/model/MultVae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mCv8FlueQQJ"
   },
   "outputs": [],
   "source": [
    "new_vae.predict(np.array(x_train[0].todense()).reshape((1,x_train.shape[1])).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hI4yAk-EeQQP"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# vae.load_weights('/content/drive/My Drive/Colab Notebooks/Data/tmp/training/cp-latest-MULTVAE.h5')\n",
    "vae.load_weights('/content/drive/My Drive/Colab Notebooks/Data/tmp/training/cp-latest-MULTVAE-TRAIN-2WITHSOFTTMAX.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VU4PVYNGNBTf"
   },
   "source": [
    "### Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "kLO6ESD_SiU4"
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "  Generate Predictions\n",
    "'''\n",
    "def generate_predictions(vae, x_train,movies_df,k=20):\n",
    "  INPUT_DIM = x_train.shape[1]\n",
    "\n",
    "  user_ID_rand = int(np.random.randint(x_train.shape[0], size=1))\n",
    "\n",
    "\n",
    "  test = np.array(x_train[user_ID_rand].todense()).reshape((1,INPUT_DIM))\n",
    "  # _,_,z=vae.encoder(test)\n",
    "  test_reconstructed = vae.predict(test)\n",
    "  # test_reconstructed = test_reconstructed.numpy()\n",
    "  top_rated_movies_idx = x_train[user_ID_rand].indices\n",
    "  shuffle(top_rated_movies_idx)\n",
    "  \n",
    "  print(f'User liked {len(top_rated_movies_idx)} movies')\n",
    "\n",
    "  if len(top_rated_movies_idx) == 0:\n",
    "    print('Emptylist')\n",
    "  else:\n",
    "    # print(top_rated_movies_idx)\n",
    "    sorted_ratings = test_reconstructed[0].tolist()\n",
    "\n",
    "    top_predicted_movies_idx = sorted(range(len(sorted_ratings)), key=lambda i: sorted_ratings[i])[-k:]\n",
    "    # print(top_predicted_movies_idx)\n",
    "\n",
    "  print('Liked')\n",
    "  count=0\n",
    "  for i in top_rated_movies_idx:\n",
    "    print(movies_df.iloc[i]['movieId'], end= ' ')\n",
    "    count += 1\n",
    "    if count >20:\n",
    "      break\n",
    "  print() \n",
    "  print('Predicted')\n",
    "  for i in top_predicted_movies_idx:\n",
    "    print(movies_df.iloc[i]['movieId'], end= ' ')\n",
    "  print() \n",
    "\n",
    "  count=0\n",
    "  for i in top_rated_movies_idx:\n",
    "\n",
    "    print(movies_df[movies_df.movieId == movies_df.iloc[i]['movieId']]['title'].values, end= '->')\n",
    "    print(movies_df[movies_df.movieId ==  movies_df.iloc[i]['movieId']]['genres'].values)\n",
    "    count += 1\n",
    "    if count >20:\n",
    "      break\n",
    "    # print(movies_df[movies_df.movieId ==  movie_dataset_df.columns[i]].head())\n",
    "    # print(i)\n",
    "    # print(movie_dataset_df.columns[i])\n",
    "  print('*'*100)\n",
    "  for i in top_predicted_movies_idx:\n",
    "    if i in top_rated_movies_idx:\n",
    "      print(\"****IN USER PREFERENCE****\", end=\"->\")\n",
    "      print(movies_df[movies_df.movieId == movies_df.iloc[i]['movieId']]['title'].values, end= '->')\n",
    "      print(movies_df[movies_df.movieId ==  movies_df.iloc[i]['movieId']]['genres'].values)\n",
    "\n",
    "    else:\n",
    "      print(movies_df[movies_df.movieId == movies_df.iloc[i]['movieId']]['title'].values, end= '->')\n",
    "      print(movies_df[movies_df.movieId ==  movies_df.iloc[i]['movieId']]['genres'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oj7JfN8vYNZo",
    "outputId": "c64f900d-0a0b-44a0-94d1-a935aff82f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]]\n",
      "[[0.4455937  0.15677905 0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "test = np.array(y_train[1].todense()).reshape((1,62000))\n",
    "pred = vae.predict(test)\n",
    "\n",
    "print(test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbjCLrndZLt_",
    "outputId": "f62245bd-4dbc-40f4-d78c-222f3662713c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0266626"
      ]
     },
     "execution_count": 213,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "max(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUnKlTIdkIvA",
    "outputId": "4722974d-99e8-4da4-d694-31be755d30fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User liked 54 movies\n",
      "Liked\n",
      "10 19 21 34 39 47 50 78 110 111 150 153 161 165 185 208 225 231 253 288 292 \n",
      "Predicted\n",
      "110 329 292 10 356 434 454 165 380 161 590 153 349 457 592 \n",
      "['GoldenEye (1995)']->['Action|Adventure|Thriller']\n",
      "['Ace Ventura: When Nature Calls (1995)']->['Comedy']\n",
      "['Get Shorty (1995)']->['Comedy|Crime|Thriller']\n",
      "['Babe (1995)']->['Children|Drama']\n",
      "['Clueless (1995)']->['Comedy|Romance']\n",
      "['Seven (a.k.a. Se7en) (1995)']->['Mystery|Thriller']\n",
      "['Usual Suspects, The (1995)']->['Crime|Mystery|Thriller']\n",
      "['Crossing Guard, The (1995)']->['Action|Crime|Drama|Thriller']\n",
      "['Braveheart (1995)']->['Action|Drama|War']\n",
      "['Taxi Driver (1976)']->['Crime|Drama|Thriller']\n",
      "['Apollo 13 (1995)']->['Adventure|Drama|IMAX']\n",
      "['Batman Forever (1995)']->['Action|Adventure|Comedy|Crime']\n",
      "['Crimson Tide (1995)']->['Drama|Thriller|War']\n",
      "['Die Hard: With a Vengeance (1995)']->['Action|Crime|Thriller']\n",
      "['Net, The (1995)']->['Action|Crime|Thriller']\n",
      "['Waterworld (1995)']->['Action|Adventure|Sci-Fi']\n",
      "['Disclosure (1994)']->['Drama|Thriller']\n",
      "['Dumb & Dumber (Dumb and Dumber) (1994)']->['Adventure|Comedy']\n",
      "['Interview with the Vampire: The Vampire Chronicles (1994)']->['Drama|Horror']\n",
      "['Natural Born Killers (1994)']->['Action|Crime|Thriller']\n",
      "['Outbreak (1995)']->['Action|Drama|Sci-Fi|Thriller']\n",
      "****************************************************************************************************\n",
      "****IN USER PREFERENCE****->['Braveheart (1995)']->['Action|Drama|War']\n",
      "****IN USER PREFERENCE****->['Star Trek: Generations (1994)']->['Adventure|Drama|Sci-Fi']\n",
      "****IN USER PREFERENCE****->['Outbreak (1995)']->['Action|Drama|Sci-Fi|Thriller']\n",
      "****IN USER PREFERENCE****->['GoldenEye (1995)']->['Action|Adventure|Thriller']\n",
      "['Forrest Gump (1994)']->['Comedy|Drama|Romance|War']\n",
      "****IN USER PREFERENCE****->['Cliffhanger (1993)']->['Action|Adventure|Thriller']\n",
      "****IN USER PREFERENCE****->['Firm, The (1993)']->['Drama|Thriller']\n",
      "****IN USER PREFERENCE****->['Die Hard: With a Vengeance (1995)']->['Action|Crime|Thriller']\n",
      "****IN USER PREFERENCE****->['True Lies (1994)']->['Action|Adventure|Comedy|Romance|Thriller']\n",
      "****IN USER PREFERENCE****->['Crimson Tide (1995)']->['Drama|Thriller|War']\n",
      "****IN USER PREFERENCE****->['Dances with Wolves (1990)']->['Adventure|Drama|Western']\n",
      "****IN USER PREFERENCE****->['Batman Forever (1995)']->['Action|Adventure|Comedy|Crime']\n",
      "****IN USER PREFERENCE****->['Clear and Present Danger (1994)']->['Action|Crime|Drama|Thriller']\n",
      "****IN USER PREFERENCE****->['Fugitive, The (1993)']->['Thriller']\n",
      "****IN USER PREFERENCE****->['Batman (1989)']->['Action|Crime|Thriller']\n"
     ]
    }
   ],
   "source": [
    "generate_predictions(vae,y_train,  movies_df, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ljeo_tpHQOi5",
    "outputId": "42072f7b-8eb0-498d-d944-f8272e8c16f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User liked 22 movies\n",
      "Liked\n",
      "1 318 356 480 1866 1892 1902 2335 2553 2675 2743 2939 3896 4002 4344 4615 4697 4753 4863 4940 4950 \n",
      "Predicted\n",
      "356 480 2939 1720 3558 1902 527 318 593 4970 5926 3773 3445 2553 3012 \n",
      "['Toy Story (1995)']->['Adventure|Animation|Children|Comedy|Fantasy']\n",
      "['Shawshank Redemption, The (1994)']->['Crime|Drama']\n",
      "['Forrest Gump (1994)']->['Comedy|Drama|Romance|War']\n",
      "['Jurassic Park (1993)']->['Action|Adventure|Sci-Fi|Thriller']\n",
      "['Big Hit, The (1998)']->['Action|Comedy|Crime']\n",
      "['Perfect Murder, A (1998)']->['Thriller']\n",
      "['Dream for an Insomniac (1996)']->['Drama|Romance']\n",
      "['Waterboy, The (1998)']->['Comedy']\n",
      "['Village of the Damned (1960)']->['Horror|Sci-Fi|Thriller']\n",
      "['Twice Upon a Yesterday (a.k.a. Man with Rain in His Shoes, The) (1998)']->['Comedy|Drama|Romance']\n",
      "['Native Son (1986)']->['Drama']\n",
      "['Niagara (1953)']->['Drama|Thriller']\n",
      "['Way of the Gun, The (2000)']->['Crime|Thriller']\n",
      "['Planes, Trains & Automobiles (1987)']->['Comedy']\n",
      "['Swordfish (2001)']->['Action|Crime|Drama']\n",
      "['Last Exit to Brooklyn (1989)']->['Drama']\n",
      "['Basket Case (1982)']->['Comedy|Horror']\n",
      "['Vamp (1986)']->['Comedy|Horror']\n",
      "['Female Trouble (1975)']->['Comedy|Crime']\n",
      "['First Deadly Sin, The (1980)']->['Thriller']\n",
      "['Lone Wolf McQuade (1983)']->['Action']\n",
      "****************************************************************************************************\n",
      "****IN USER PREFERENCE****->['Forrest Gump (1994)']->['Comedy|Drama|Romance|War']\n",
      "****IN USER PREFERENCE****->['Jurassic Park (1993)']->['Action|Adventure|Sci-Fi|Thriller']\n",
      "****IN USER PREFERENCE****->['Niagara (1953)']->['Drama|Thriller']\n",
      "['Time Tracers (1995)']->['Action|Adventure|Sci-Fi']\n",
      "['Law, The (a.k.a. Where the Hot Wind Blows!) (Legge, La) (1958)']->['Drama']\n",
      "****IN USER PREFERENCE****->['Dream for an Insomniac (1996)']->['Drama|Romance']\n",
      "[\"Schindler's List (1993)\"]->['Drama|War']\n",
      "****IN USER PREFERENCE****->['Shawshank Redemption, The (1994)']->['Crime|Drama']\n",
      "['Silence of the Lambs, The (1991)']->['Crime|Horror|Thriller']\n",
      "['Blue Angel, The (Blaue Engel, Der) (1930)']->['Drama']\n",
      "['Best Friends (1982)']->['Comedy|Drama|Romance']\n",
      "['House Party (1990)']->['Comedy']\n",
      "['Eyes of Laura Mars (1978)']->['Mystery|Thriller']\n",
      "****IN USER PREFERENCE****->['Village of the Damned (1960)']->['Horror|Sci-Fi|Thriller']\n",
      "['Battling Butler (1926)']->['Comedy']\n"
     ]
    }
   ],
   "source": [
    "generate_predictions(vae,y_train,  movies_df, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H59PIzOhQQeI",
    "outputId": "025e04f1-8895-4534-cbca-94b663cd2c34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User liked 287 movies\n",
      "Liked\n",
      "2 10 17 21 32 34 47 48 50 70 111 163 196 235 247 253 260 273 293 296 313 \n",
      "Predicted\n",
      "1251 296 2697 110 1263 1031 1232 2838 1202 260 589 2013 593 2743 1207 \n",
      "['Jumanji (1995)']->['Adventure|Children|Fantasy']\n",
      "['GoldenEye (1995)']->['Action|Adventure|Thriller']\n",
      "['Sense and Sensibility (1995)']->['Drama|Romance']\n",
      "['Get Shorty (1995)']->['Comedy|Crime|Thriller']\n",
      "['Twelve Monkeys (a.k.a. 12 Monkeys) (1995)']->['Mystery|Sci-Fi|Thriller']\n",
      "['Babe (1995)']->['Children|Drama']\n",
      "['Seven (a.k.a. Se7en) (1995)']->['Mystery|Thriller']\n",
      "['Pocahontas (1995)']->['Animation|Children|Drama|Musical|Romance']\n",
      "['Usual Suspects, The (1995)']->['Crime|Mystery|Thriller']\n",
      "['From Dusk Till Dawn (1996)']->['Action|Comedy|Horror|Thriller']\n",
      "['Taxi Driver (1976)']->['Crime|Drama|Thriller']\n",
      "['Desperado (1995)']->['Action|Romance|Western']\n",
      "['Species (1995)']->['Horror|Sci-Fi']\n",
      "['Ed Wood (1994)']->['Comedy|Drama']\n",
      "['Heavenly Creatures (1994)']->['Crime|Drama']\n",
      "['Interview with the Vampire: The Vampire Chronicles (1994)']->['Drama|Horror']\n",
      "['Star Wars: Episode IV - A New Hope (1977)']->['Action|Adventure|Sci-Fi']\n",
      "[\"Mary Shelley's Frankenstein (Frankenstein) (1994)\"]->['Drama|Horror|Sci-Fi']\n",
      "['Léon: The Professional (a.k.a. The Professional) (Léon) (1994)']->['Action|Crime|Drama|Thriller']\n",
      "['Pulp Fiction (1994)']->['Comedy|Crime|Drama|Thriller']\n",
      "['Swan Princess, The (1994)']->['Animation|Children']\n",
      "****************************************************************************************************\n",
      "****IN USER PREFERENCE****->['8 1/2 (8½) (1963)']->['Drama|Fantasy']\n",
      "****IN USER PREFERENCE****->['Pulp Fiction (1994)']->['Comedy|Crime|Drama|Thriller']\n",
      "****IN USER PREFERENCE****->['My Son the Fanatic (1997)']->['Comedy|Drama|Romance']\n",
      "['Braveheart (1995)']->['Action|Drama|War']\n",
      "['Deer Hunter, The (1978)']->['Drama|War']\n",
      "['Bedknobs and Broomsticks (1971)']->['Adventure|Children|Musical']\n",
      "****IN USER PREFERENCE****->['Stalker (1979)']->['Drama|Mystery|Sci-Fi']\n",
      "****IN USER PREFERENCE****->['I Woke Up Early the Day I Died (1998)']->['Comedy|Crime|Thriller']\n",
      "****IN USER PREFERENCE****->['Withnail & I (1987)']->['Comedy']\n",
      "****IN USER PREFERENCE****->['Star Wars: Episode IV - A New Hope (1977)']->['Action|Adventure|Sci-Fi']\n",
      "****IN USER PREFERENCE****->['Terminator 2: Judgment Day (1991)']->['Action|Sci-Fi']\n",
      "['Poseidon Adventure, The (1972)']->['Action|Adventure|Drama']\n",
      "****IN USER PREFERENCE****->['Silence of the Lambs, The (1991)']->['Crime|Horror|Thriller']\n",
      "['Native Son (1986)']->['Drama']\n",
      "****IN USER PREFERENCE****->['To Kill a Mockingbird (1962)']->['Drama']\n"
     ]
    }
   ],
   "source": [
    "generate_predictions(vae,y_train,  movies_df, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RuaAOCuWQSuK",
    "outputId": "03fc90dc-f9f3-48e6-a44b-a8b8a885d5f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User liked 25 movies\n",
      "Liked\n",
      "1670 58246 59014 59832 62439 68572 72731 78776 101680 101880 102417 102878 104280 106094 108885 109529 110568 111852 111924 112279 116345 \n",
      "Predicted\n",
      "116413 114875 133735 98294 58246 106234 112279 81537 161054 109529 89371 78776 108885 83613 122567 \n",
      "['Welcome to Sarajevo (1997)']->['Drama|War']\n",
      "['Grace Is Gone (2007)']->['Drama']\n",
      "['Superhero Movie (2008)']->['Action|Comedy|Sci-Fi']\n",
      "['Where the Sidewalk Ends (1950)']->['Crime|Drama|Film-Noir']\n",
      "[\"My Best Friend's Girl (2008)\"]->['Comedy|Romance']\n",
      "['Kids in the Hall: Same Guys, New Dresses (2001)']->['Comedy|Documentary']\n",
      "['Lovely Bones, The (2009)']->['Crime|Drama|Fantasy|Horror|Thriller']\n",
      "['Hannah Free (2009)']->['Drama']\n",
      "['Copper Mountain (1983)']->['Comedy|Musical']\n",
      "['Siberian Education (Educazione siberiana) (2013)']->['Drama']\n",
      "['Sicily! (Sicilia!) (1999)']->['Drama']\n",
      "['Global Affair, A (1964)']->['Comedy']\n",
      "['Black Room, The (1935)']->['Crime|Horror|Thriller']\n",
      "['Godzilla: Tokyo S.O.S. (Gojira tai Mosura tai Mekagojira: Tôkyô S.O.S.) (2003)']->['Action|Fantasy|Sci-Fi']\n",
      "['Asier ETA biok (2013)']->['Documentary']\n",
      "['Everybody Street (2013)']->['Documentary']\n",
      "['Terror Beneath the Sea, The (Kaitei daisensô) (1966)']->['Action|Sci-Fi']\n",
      "['Generation Iron (2013)']->['Documentary']\n",
      "['Grand Seduction, The (2013)']->['Comedy']\n",
      "['Doc of the Dead (2014)']->['Documentary']\n",
      "[\"Dakota's Summer (2014)\"]->['Children']\n",
      "****************************************************************************************************\n",
      "['Life Partners (2014)']->['Comedy|Romance']\n",
      "['Crimes of the Future (1970)']->['Comedy|Sci-Fi']\n",
      "****IN USER PREFERENCE****->['Betty Blowtorch: And Her Amazing True Life Adventures (2003)']->['Documentary']\n",
      "['Tokio Baby (2010)']->['Drama']\n",
      "****IN USER PREFERENCE****->['Grace Is Gone (2007)']->['Drama']\n",
      "['Great Expectations (2012)']->['Drama']\n",
      "****IN USER PREFERENCE****->['Doc of the Dead (2014)']->['Documentary']\n",
      "['Due Date (2010)']->['Comedy']\n",
      "['The Sons of Great Bear (1966)']->['Action|Drama|Western']\n",
      "****IN USER PREFERENCE****->['Everybody Street (2013)']->['Documentary']\n",
      "['Raging Phoenix (Deu suay doo) (2009)']->['Action|Romance']\n",
      "****IN USER PREFERENCE****->['Hannah Free (2009)']->['Drama']\n",
      "****IN USER PREFERENCE****->['Asier ETA biok (2013)']->['Documentary']\n",
      "['Cowboys & Aliens (2011)']->['Action|Sci-Fi|Thriller|Western|IMAX']\n",
      "['In The Dark (2013)']->['Horror']\n"
     ]
    }
   ],
   "source": [
    "generate_predictions(vae,y_train,  movies_df, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlv-aT_tQUga",
    "outputId": "dce3843f-4268-4490-89e9-cbe8b40e4e4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User liked 100 movies\n",
      "Liked\n",
      "39 318 364 500 527 597 1024 1189 1670 1892 2044 2066 2129 2554 2652 3862 4425 4863 4873 5592 5595 \n",
      "Predicted\n",
      "69542 134437 62439 97457 98294 68572 58246 83613 135127 161054 89371 122567 109529 81537 78776 \n",
      "['Clueless (1995)']->['Comedy|Romance']\n",
      "['Shawshank Redemption, The (1994)']->['Crime|Drama']\n",
      "['Lion King, The (1994)']->['Adventure|Animation|Children|Drama|Musical|IMAX']\n",
      "['Mrs. Doubtfire (1993)']->['Comedy|Drama']\n",
      "[\"Schindler's List (1993)\"]->['Drama|War']\n",
      "['Pretty Woman (1990)']->['Comedy|Romance']\n",
      "['Three Caballeros, The (1945)']->['Animation|Children|Musical']\n",
      "['Thin Blue Line, The (1988)']->['Documentary']\n",
      "['Welcome to Sarajevo (1997)']->['Drama|War']\n",
      "['Perfect Murder, A (1998)']->['Thriller']\n",
      "['Devil and Max Devlin, The (1981)']->['Comedy|Fantasy']\n",
      "['Out of the Past (1947)']->['Film-Noir']\n",
      "['Saltmen of Tibet, The (Salzmänner von Tibet, Die) (1997)']->['Documentary']\n",
      "['Children of the Damned (1963)']->['Horror|Sci-Fi|Thriller']\n",
      "['Curse of Frankenstein, The (1957)']->['Horror']\n",
      "['About Adam (2000)']->['Comedy']\n",
      "['Howling III: The Marsupials (1987)']->['Comedy|Horror']\n",
      "['Female Trouble (1975)']->['Comedy|Crime']\n",
      "['Waking Life (2001)']->['Animation|Drama|Fantasy']\n",
      "['Monster in the Closet (1986)']->['Comedy|Horror']\n",
      "['Shock Waves (1977)']->['Horror']\n",
      "****************************************************************************************************\n",
      "****IN USER PREFERENCE****->['K2 (1991)']->['Adventure|Drama']\n",
      "****IN USER PREFERENCE****->['Mollo Tutto (1995)']->['Comedy']\n",
      "[\"My Best Friend's Girl (2008)\"]->['Comedy|Romance']\n",
      "****IN USER PREFERENCE****->['Reluctant Saint, The (1962)']->['Comedy|Drama']\n",
      "['Tokio Baby (2010)']->['Drama']\n",
      "****IN USER PREFERENCE****->['Kids in the Hall: Same Guys, New Dresses (2001)']->['Comedy|Documentary']\n",
      "['Grace Is Gone (2007)']->['Drama']\n",
      "['Cowboys & Aliens (2011)']->['Action|Sci-Fi|Thriller|Western|IMAX']\n",
      "['Metro (2013)']->['Action|Thriller']\n",
      "['The Sons of Great Bear (1966)']->['Action|Drama|Western']\n",
      "****IN USER PREFERENCE****->['Raging Phoenix (Deu suay doo) (2009)']->['Action|Romance']\n",
      "****IN USER PREFERENCE****->['In The Dark (2013)']->['Horror']\n",
      "****IN USER PREFERENCE****->['Everybody Street (2013)']->['Documentary']\n",
      "****IN USER PREFERENCE****->['Due Date (2010)']->['Comedy']\n",
      "****IN USER PREFERENCE****->['Hannah Free (2009)']->['Drama']\n"
     ]
    }
   ],
   "source": [
    "generate_predictions(vae,y_train,  movies_df, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqrg5fYnQWb0",
    "outputId": "145867ef-edd4-49ef-fb1a-e88968436e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User liked 96 movies\n",
      "Liked\n",
      "1 19 50 110 150 161 296 344 356 377 380 480 592 593 607 670 733 776 1252 1568 1574 \n",
      "Predicted\n",
      "6513 1189 1263 2743 480 3012 2939 356 260 7126 5926 318 4970 593 2553 \n",
      "['Toy Story (1995)']->['Adventure|Animation|Children|Comedy|Fantasy']\n",
      "['Ace Ventura: When Nature Calls (1995)']->['Comedy']\n",
      "['Usual Suspects, The (1995)']->['Crime|Mystery|Thriller']\n",
      "['Braveheart (1995)']->['Action|Drama|War']\n",
      "['Apollo 13 (1995)']->['Adventure|Drama|IMAX']\n",
      "['Crimson Tide (1995)']->['Drama|Thriller|War']\n",
      "['Pulp Fiction (1994)']->['Comedy|Crime|Drama|Thriller']\n",
      "['Ace Ventura: Pet Detective (1994)']->['Comedy']\n",
      "['Forrest Gump (1994)']->['Comedy|Drama|Romance|War']\n",
      "['Speed (1994)']->['Action|Romance|Thriller']\n",
      "['True Lies (1994)']->['Action|Adventure|Comedy|Romance|Thriller']\n",
      "['Jurassic Park (1993)']->['Action|Adventure|Sci-Fi|Thriller']\n",
      "['Batman (1989)']->['Action|Crime|Thriller']\n",
      "['Silence of the Lambs, The (1991)']->['Crime|Horror|Thriller']\n",
      "['Century (1993)']->['Drama']\n",
      "['World of Apu, The (Apur Sansar) (1959)']->['Drama']\n",
      "['Rock, The (1996)']->['Action|Adventure|Thriller']\n",
      "['Babyfever (1994)']->['Comedy|Drama']\n",
      "['Chinatown (1974)']->['Crime|Film-Noir|Mystery|Thriller']\n",
      "['MURDER and murder (1996)']->['Crime|Drama|Mystery']\n",
      "['Fall (1997)']->['Romance']\n",
      "****************************************************************************************************\n",
      "****IN USER PREFERENCE****->['Made for Each Other (1939)']->['Comedy|Drama|Romance']\n",
      "['Thin Blue Line, The (1988)']->['Documentary']\n",
      "['Deer Hunter, The (1978)']->['Drama|War']\n",
      "****IN USER PREFERENCE****->['Native Son (1986)']->['Drama']\n",
      "****IN USER PREFERENCE****->['Jurassic Park (1993)']->['Action|Adventure|Sci-Fi|Thriller']\n",
      "['Battling Butler (1926)']->['Comedy']\n",
      "['Niagara (1953)']->['Drama|Thriller']\n",
      "****IN USER PREFERENCE****->['Forrest Gump (1994)']->['Comedy|Drama|Romance|War']\n",
      "['Star Wars: Episode IV - A New Hope (1977)']->['Action|Adventure|Sci-Fi']\n",
      "****IN USER PREFERENCE****->['Killing of a Chinese Bookie, The (1976)']->['Comedy|Crime|Drama|Film-Noir|Musical']\n",
      "****IN USER PREFERENCE****->['Best Friends (1982)']->['Comedy|Drama|Romance']\n",
      "['Shawshank Redemption, The (1994)']->['Crime|Drama']\n",
      "****IN USER PREFERENCE****->['Blue Angel, The (Blaue Engel, Der) (1930)']->['Drama']\n",
      "****IN USER PREFERENCE****->['Silence of the Lambs, The (1991)']->['Crime|Horror|Thriller']\n",
      "****IN USER PREFERENCE****->['Village of the Damned (1960)']->['Horror|Sci-Fi|Thriller']\n"
     ]
    }
   ],
   "source": [
    "generate_predictions(vae,y_train,  movies_df, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izmQoaY6QYYY",
    "outputId": "c97acbd6-da6d-4c7f-83a3-015ec485c8d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User liked 520 movies\n",
      "Liked\n",
      "1 5 10 19 39 47 48 95 110 145 153 161 185 204 208 231 260 316 318 349 350 \n",
      "Predicted\n",
      "80290 4863 4284 45335 5435 1202 1568 6513 116413 45003 3979 53582 999 1284 69945 \n",
      "['Toy Story (1995)']->['Adventure|Animation|Children|Comedy|Fantasy']\n",
      "['Father of the Bride Part II (1995)']->['Comedy']\n",
      "['GoldenEye (1995)']->['Action|Adventure|Thriller']\n",
      "['Ace Ventura: When Nature Calls (1995)']->['Comedy']\n",
      "['Clueless (1995)']->['Comedy|Romance']\n",
      "['Seven (a.k.a. Se7en) (1995)']->['Mystery|Thriller']\n",
      "['Pocahontas (1995)']->['Animation|Children|Drama|Musical|Romance']\n",
      "['Broken Arrow (1996)']->['Action|Adventure|Thriller']\n",
      "['Braveheart (1995)']->['Action|Drama|War']\n",
      "['Bad Boys (1995)']->['Action|Comedy|Crime|Drama|Thriller']\n",
      "['Batman Forever (1995)']->['Action|Adventure|Comedy|Crime']\n",
      "['Crimson Tide (1995)']->['Drama|Thriller|War']\n",
      "['Net, The (1995)']->['Action|Crime|Thriller']\n",
      "['Under Siege 2: Dark Territory (1995)']->['Action']\n",
      "['Waterworld (1995)']->['Action|Adventure|Sci-Fi']\n",
      "['Dumb & Dumber (Dumb and Dumber) (1994)']->['Adventure|Comedy']\n",
      "['Star Wars: Episode IV - A New Hope (1977)']->['Action|Adventure|Sci-Fi']\n",
      "['Stargate (1994)']->['Action|Adventure|Sci-Fi']\n",
      "['Shawshank Redemption, The (1994)']->['Crime|Drama']\n",
      "['Clear and Present Danger (1994)']->['Action|Crime|Drama|Thriller']\n",
      "['Client, The (1994)']->['Drama|Mystery|Thriller']\n",
      "****************************************************************************************************\n",
      "[\"It's a Great Feeling (1949)\"]->['Comedy']\n",
      "****IN USER PREFERENCE****->['Female Trouble (1975)']->['Comedy|Crime']\n",
      "****IN USER PREFERENCE****->['Frankie and Johnny (1966)']->['Comedy']\n",
      "****IN USER PREFERENCE****->['Footlight Parade (1933)']->['Comedy|Musical|Romance']\n",
      "['Hombre (1967)']->['Western']\n",
      "['Withnail & I (1987)']->['Comedy']\n",
      "****IN USER PREFERENCE****->['MURDER and murder (1996)']->['Crime|Drama|Mystery']\n",
      "****IN USER PREFERENCE****->['Made for Each Other (1939)']->['Comedy|Drama|Romance']\n",
      "['Life Partners (2014)']->['Comedy|Romance']\n",
      "['Shutter (2004)']->['Fantasy|Horror|Mystery|Thriller']\n",
      "['Little Nicky (2000)']->['Comedy']\n",
      "****IN USER PREFERENCE****->['Dodge City (1939)']->['Romance|Western']\n",
      "['2 Days in the Valley (1996)']->['Crime|Film-Noir']\n",
      "****IN USER PREFERENCE****->['Big Sleep, The (1946)']->['Crime|Film-Noir|Mystery']\n",
      "['Fast and the Furious, The (1955)']->['Crime|Mystery']\n"
     ]
    }
   ],
   "source": [
    "generate_predictions(vae,y_train,  movies_df, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZRTIi9DQaKZ",
    "outputId": "53794c21-6017-480b-cecb-e03c249dbc89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User liked 344 movies\n",
      "Liked\n",
      "29 70 110 213 260 266 293 296 356 509 518 539 588 589 594 595 596 615 713 779 853 \n",
      "Predicted\n",
      "27664 3483 4950 4970 853 527 919 1168 1272 776 747 3287 260 541 1705 \n",
      "['City of Lost Children, The (Cité des enfants perdus, La) (1995)']->['Adventure|Drama|Fantasy|Mystery|Sci-Fi']\n",
      "['From Dusk Till Dawn (1996)']->['Action|Comedy|Horror|Thriller']\n",
      "['Braveheart (1995)']->['Action|Drama|War']\n",
      "['Burnt by the Sun (Utomlyonnye solntsem) (1994)']->['Drama']\n",
      "['Star Wars: Episode IV - A New Hope (1977)']->['Action|Adventure|Sci-Fi']\n",
      "['Legends of the Fall (1994)']->['Drama|Romance|War|Western']\n",
      "['Léon: The Professional (a.k.a. The Professional) (Léon) (1994)']->['Action|Crime|Drama|Thriller']\n",
      "['Pulp Fiction (1994)']->['Comedy|Crime|Drama|Thriller']\n",
      "['Forrest Gump (1994)']->['Comedy|Drama|Romance|War']\n",
      "['Piano, The (1993)']->['Drama|Romance']\n",
      "['Road to Wellville, The (1994)']->['Comedy']\n",
      "['Sleepless in Seattle (1993)']->['Comedy|Drama|Romance']\n",
      "['Aladdin (1992)']->['Adventure|Animation|Children|Comedy|Musical']\n",
      "['Terminator 2: Judgment Day (1991)']->['Action|Sci-Fi']\n",
      "['Snow White and the Seven Dwarfs (1937)']->['Animation|Children|Drama|Fantasy|Musical']\n",
      "['Beauty and the Beast (1991)']->['Animation|Children|Fantasy|Musical|Romance|IMAX']\n",
      "['Pinocchio (1940)']->['Animation|Children|Fantasy|Musical']\n",
      "['Bread and Chocolate (Pane e cioccolata) (1973)']->['Comedy|Drama']\n",
      "['Of Love and Shadows (1994)']->['Drama']\n",
      "[\"'Til There Was You (1997)\"]->['Drama|Romance']\n",
      "['Dingo (1991)']->['Drama']\n",
      "****************************************************************************************************\n",
      "['Brown Bunny, The (2003)']->['Drama']\n",
      "****IN USER PREFERENCE****->['Road to El Dorado, The (2000)']->['Animation|Children']\n",
      "****IN USER PREFERENCE****->['Lone Wolf McQuade (1983)']->['Action']\n",
      "****IN USER PREFERENCE****->['Blue Angel, The (Blaue Engel, Der) (1930)']->['Drama']\n",
      "****IN USER PREFERENCE****->['Dingo (1991)']->['Drama']\n",
      "[\"Schindler's List (1993)\"]->['Drama|War']\n",
      "****IN USER PREFERENCE****->['Wizard of Oz, The (1939)']->['Adventure|Children|Fantasy|Musical']\n",
      "****IN USER PREFERENCE****->['Bad Moon (1996)']->['Action|Adventure|Horror']\n",
      "['Patton (1970)']->['Drama|War']\n",
      "['Babyfever (1994)']->['Comedy|Drama']\n",
      "['Stupids, The (1996)']->['Comedy']\n",
      "['Tigger Movie, The (2000)']->['Animation|Children']\n",
      "****IN USER PREFERENCE****->['Star Wars: Episode IV - A New Hope (1977)']->['Action|Adventure|Sci-Fi']\n",
      "['Blade Runner (1982)']->['Action|Sci-Fi|Thriller']\n",
      "['Guy (1997)']->['Drama']\n"
     ]
    }
   ],
   "source": [
    "generate_predictions(vae,y_train,  movies_df, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prO-3PAMNGMO"
   },
   "source": [
    "### Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OD0ZoHW8Xaj7",
    "outputId": "6295bc3f-d042-4947-c39c-0062066a0b86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "size = 1000\n",
    "ndcg= []\n",
    "recall=[]\n",
    "for i in tqdm(range(10)):\n",
    "  x_test_matrix_sparse = test_dataset_sparse[i*size:(i+1)*size]\n",
    "  x_test_matrix = np.array(x_test_matrix_sparse.todense() ) \n",
    "  x_test_reconstructed = vae.predict(x_test_matrix)  # float values per user\n",
    "\n",
    "  ndcg.append(np.mean(NDCG_binary_at_k_batch(x_test_reconstructed, x_test_matrix_sparse, 100)))\n",
    "  recall.append(np.mean(Recall_at_k_batch(x_test_reconstructed, x_test_matrix_sparse,20)))\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYbM87QxYFMM",
    "outputId": "e58b75a7-616b-45b1-d44a-74eb8903bf38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECALL: 0.5094955263157895\n",
      "NDCG: 0.49558543182374015\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"RECALL: \"+str(np.mean(recall)))\n",
    "print(\"NDCG: \"+str(np.mean(ndcg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fijnIG2TmCUe",
    "outputId": "91a65b57-ba19-4d20-91e0-9eb559041f18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 62000)\n",
      "(1000, 62000)\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "x_test_matrix_sparse = test_dataset_sparse[4000:5000]\n",
    "x_test_matrix = np.array(x_test_matrix_sparse.todense() ) \n",
    "\n",
    "\n",
    "x_test_reconstructed = vae.predict(x_test_matrix)  # float values per user\n",
    "print(x_test_matrix.shape)\n",
    "print(x_test_reconstructed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sl7t-EkymCUw",
    "outputId": "df5bbf24-88ed-4447-ae9e-51dd05bb4c0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:18<00:00, 54.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33885060703488"
      ]
     },
     "execution_count": 227,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcgatk(x_test_matrix, x_test_reconstructed, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2eoW5uYemCU3",
    "outputId": "58f357de-5198-492f-803f-bcfa3302d191"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:18<00:00, 53.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5298000000000004"
      ]
     },
     "execution_count": 228,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recallatk(x_test_matrix, x_test_reconstructed,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "FXudD8emmHig"
   },
   "outputs": [],
   "source": [
    "ndcg = NDCG_binary_at_k_batch(x_test_reconstructed, x_test_matrix_sparse, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "g5Y-_F7xKvu-"
   },
   "outputs": [],
   "source": [
    "recall = Recall_at_k_batch(x_test_reconstructed, x_test_matrix_sparse,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_jdQ1EQPNEb",
    "outputId": "c126ff15-d1a3-4ddd-c5ae-d3f816cd8e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5104991262707413\n",
      "0.5297999999999999\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(ndcg))\n",
    "print(np.mean(recall))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JCIEBIaZNjk"
   },
   "source": [
    "## TFJS CONVERSSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wnmQPi9ZVmZ",
    "outputId": "74d65c3f-da28-4602-be2e-6267f54ad94f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowjs\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/4e/f9a147cbf1694b76ac5d2689bbaecf4f70a98712908474ea733d2f545f61/tensorflowjs-3.1.0-py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 3.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.0)\n",
      "Requirement already satisfied: h5py<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.10.0)\n",
      "Collecting tensorflow-hub<0.10,>=0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/83/a7df82744a794107641dad1decaad017d82e25f0e1f761ac9204829eef96/tensorflow_hub-0.9.0-py2.py3-none-any.whl (103kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 7.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.4.1)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py<3,>=2.8.0->tensorflowjs) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (3.12.4)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.36.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.32.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.10.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (53.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.25.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.0)\n",
      "Installing collected packages: tensorflow-hub, tensorflowjs\n",
      "  Found existing installation: tensorflow-hub 0.11.0\n",
      "    Uninstalling tensorflow-hub-0.11.0:\n",
      "      Successfully uninstalled tensorflow-hub-0.11.0\n",
      "Successfully installed tensorflow-hub-0.9.0 tensorflowjs-3.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "5AabYhmdZQcF"
   },
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkkcxH8aZpCn",
    "outputId": "0f61bafc-6c4d-4474-a0c9-91f533ff809b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing weight file /content/drive/MyDrive/Colab Notebooks/Data/tmp/model/VAEModel/js/model.json...\n"
     ]
    }
   ],
   "source": [
    "# tfjs.converters.convert_tf_saved_model('/content/drive/My Drive/Colab Notebooks/Data/tmp/model/MultVae', '/content/drive/My Drive/Colab Notebooks/Data/tmp/model/MultVae1/js')\n",
    "tfjs.converters.convert_tf_saved_model('/content/tmp/model/New', '/content/drive/MyDrive/Colab Notebooks/Data/tmp/model/VAEModel/js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1Iy8INHp24U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-FK8S4C6kG3d"
   ],
   "name": "Recommendation Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
